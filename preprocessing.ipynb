{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changed-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/collins/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/collins/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/collins/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/collins/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # our main data management package\n",
    "import matplotlib.pyplot as plt # our main display package\n",
    "import string # used for preprocessing\n",
    "import re # used for preprocessing\n",
    "import nltk # the Natural Language Toolkit, used for preprocessing\n",
    "import numpy as np # used for managing NaNs\n",
    "import fasttext\n",
    "import contractions \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnetfrom nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords # used for preprocessing\n",
    "from nltk.stem import WordNetLemmatizer # used for preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression # our model\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in the woods...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now in the building across the street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "5   8     NaN      NaN   \n",
       "6  10     NaN      NaN   \n",
       "7  13     NaN      NaN   \n",
       "8  14     NaN      NaN   \n",
       "9  15     NaN      NaN   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                               Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in California    \n",
       "4             Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "5  #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAf...   \n",
       "6      #flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas   \n",
       "7                                          I'm on top of the hill and I can see a fire in the woods...   \n",
       "8                      There's an emergency evacuation happening now in the building across the street   \n",
       "9                                                 I'm afraid that the tornado is coming to our area...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eastern-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].map(lambda x: x.lower())\n",
    "# df['double_age'] =df['age'].map(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unable-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"all residents asked to 'shelter in place' are being notified by officers. no other evacuation or shelter in place orders are expected\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "athletic-corruption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arsenal did yesterday, eh? EH?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   0     NaN      NaN   \n",
       "1   2     NaN      NaN   \n",
       "2   3     NaN      NaN   \n",
       "3   9     NaN      NaN   \n",
       "4  11     NaN      NaN   \n",
       "5  12     NaN      NaN   \n",
       "6  21     NaN      NaN   \n",
       "7  22     NaN      NaN   \n",
       "8  27     NaN      NaN   \n",
       "9  29     NaN      NaN   \n",
       "\n",
       "                                                                                               text  \n",
       "0                                                                Just happened a terrible car crash  \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires  \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "5                                                                We're shaking...It's an earthquake  \n",
       "6                          They'd probably still show more life than Arsenal did yesterday, eh? EH?  \n",
       "7                                                                                 Hey! How are you?  \n",
       "8                                                                                  What a nice hat?  \n",
       "9                                                                                         Fuck off!  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "located-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['keyword', 'location'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electrical-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# pattern=\"[a-zA-Z0-9]+@[a-zA-Z]+\\.(com)\"\n",
    "# match=input()\n",
    "# searc=re.search(pattern,match)\n",
    "# if searc:\n",
    "#     print(\"valid!!!\")\n",
    "# else:\n",
    "#     print(\"invalid\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expired-helmet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                  Just happened a terrible car crash\n",
       "1                                    Heard about #earthquake is different cities, stay safe everyone.\n",
       "2    there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n",
       "3                                                            Apocalypse lighting. #Spokane #wildfires\n",
       "4                                                       Typhoon Soudelor kills 28 in China and Taiwan\n",
       "5                                                                  We're shaking...It's an earthquake\n",
       "6                            They'd probably still show more life than Arsenal did yesterday, eh? EH?\n",
       "7                                                                                   Hey! How are you?\n",
       "8                                                                                    What a nice hat?\n",
       "9                                                                                           Fuck off!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "miniature-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                  Just happened a terrible car crash\n",
       "1                                    Heard about #earthquake is different cities, stay safe everyone.\n",
       "2    there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all\n",
       "3                                                            Apocalypse lighting. #Spokane #wildfires\n",
       "4                                                       Typhoon Soudelor kills 28 in China and Taiwan\n",
       "5                                                                  We're shaking...It's an earthquake\n",
       "6                            They'd probably still show more life than Arsenal did yesterday, eh? EH?\n",
       "7                                                                                   Hey! How are you?\n",
       "8                                                                                    What a nice hat?\n",
       "9                                                                                           Fuck off!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bound-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 0\n",
      "text : 0\n",
      "target : 0\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    print(col,':',train[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "endangered-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text']=test.apply(lambda x: x[['text']].str.lower(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "square-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['double_age'] =train['id'].map(lambda x: x*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "engaging-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['double_age'] =train['double_age'].map(lambda x: x*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "complex-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['text'] =train['text'].map(lambda x: x.lower() if type(x)==str else x)\n",
    "train['text'] =train['text'].map(lambda x: x.lower() if isinstance(x,str)==str else x)\n",
    "# train['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "muslim-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>double_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this #earthquake may allah forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>all residents asked to 'shelter in place' are being notified by officers. no other evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in california</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>just got sent this photo from ruby #alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed in both directions due to lake county fire - #caf...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flooding of streets in manitou, colorado springs areas</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>i'm on top of the hill and i can see a fire in the woods...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>there's an emergency evacuation happening now in the building across the street</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>i'm afraid that the tornado is coming to our area...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   1   \n",
       "1   4   \n",
       "2   5   \n",
       "3   6   \n",
       "4   7   \n",
       "5   8   \n",
       "6  10   \n",
       "7  13   \n",
       "8  14   \n",
       "9  15   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0                                our deeds are the reason of this #earthquake may allah forgive us all   \n",
       "1                                                               forest fire near la ronge sask. canada   \n",
       "2  all residents asked to 'shelter in place' are being notified by officers. no other evacuation or...   \n",
       "3                                    13,000 people receive #wildfires evacuation orders in california    \n",
       "4             just got sent this photo from ruby #alaska as smoke from #wildfires pours into a school    \n",
       "5  #rockyfire update => california hwy. 20 closed in both directions due to lake county fire - #caf...   \n",
       "6      #flood #disaster heavy rain causes flash flooding of streets in manitou, colorado springs areas   \n",
       "7                                          i'm on top of the hill and i can see a fire in the woods...   \n",
       "8                      there's an emergency evacuation happening now in the building across the street   \n",
       "9                                                 i'm afraid that the tornado is coming to our area...   \n",
       "\n",
       "   target  double_age  \n",
       "0       1           4  \n",
       "1       1          16  \n",
       "2       1          20  \n",
       "3       1          24  \n",
       "4       1          28  \n",
       "5       1          32  \n",
       "6       1          40  \n",
       "7       1          52  \n",
       "8       1          56  \n",
       "9       1          60  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "serious-persian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                  just happened a terrible car crash\n",
       "1                                    heard about #earthquake is different cities, stay safe everyone.\n",
       "2    there is a forest fire at spot pond, geese are fleeing across the street, i cannot save them all\n",
       "3                                                            apocalypse lighting. #spokane #wildfires\n",
       "4                                                       typhoon soudelor kills 28 in china and taiwan\n",
       "5                                                                  we're shaking...it's an earthquake\n",
       "6                            they'd probably still show more life than arsenal did yesterday, eh? eh?\n",
       "7                                                                                   hey! how are you?\n",
       "8                                                                                    what a nice hat?\n",
       "9                                                                                           fuck off!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unlike-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding Contractions\n",
    "test['text']=test['text'].apply(lambda x:[contractions.fix(word) for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "raising-penetration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                              [just, happened, a, terrible, car, crash]\n",
       "1                             [heard, about, #earthquake, is, different, cities,, stay, safe, everyone.]\n",
       "2    [there, is, a, forest, fire, at, spot, pond,, geese, are, fleeing, across, the, street,, i, cann...\n",
       "3                                                          [apocalypse, lighting., #spokane, #wildfires]\n",
       "4                                                 [typhoon, soudelor, kills, 28, in, china, and, taiwan]\n",
       "5                                                              [we are, shaking...it is, an, earthquake]\n",
       "6              [they would, probably, still, show, more, life, than, arsenal, did, yesterday,, eh?, eh?]\n",
       "7                                                                                 [hey!, how, are, you?]\n",
       "8                                                                                  [what, a, nice, hat?]\n",
       "9                                                                                           [fuck, off!]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rubber-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded contractions to be tokenized separately \n",
    "test['text'] = [' '.join(map(str, l)) for l in test['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assumed-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                  just happened a terrible car crash\n",
       "1                                    heard about #earthquake is different cities, stay safe everyone.\n",
       "2    there is a forest fire at spot pond, geese are fleeing across the street, i cannot save them all\n",
       "3                                                            apocalypse lighting. #spokane #wildfires\n",
       "4                                                       typhoon soudelor kills 28 in china and taiwan\n",
       "5                                                                we are shaking...it is an earthquake\n",
       "6                        they would probably still show more life than arsenal did yesterday, eh? eh?\n",
       "7                                                                                   hey! how are you?\n",
       "8                                                                                    what a nice hat?\n",
       "9                                                                                           fuck off!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moving-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to know whether the text are english words\n",
    "fasttext.FastText.eprint = lambda x: None #silencing the warning message\n",
    "pretrained_model = \"lid.176.bin\" \n",
    "model = fasttext.load_model(pretrained_model)\n",
    "langs = []\n",
    "for sent in test['text']:\n",
    "    lang = model.predict(sent)[0]\n",
    "    langs.append(str(lang)[11:13])\n",
    "test['language'] = langs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vertical-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n"
     ]
    }
   ],
   "source": [
    "print(test.head().loc[:,'language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stable-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer in order to split each individual word into a token\n",
    "test['text'] = test['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "superb-verification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                              [just, happened, a, terrible, car, crash]\n",
       "1                       [heard, about, #, earthquake, is, different, cities, ,, stay, safe, everyone, .]\n",
       "2    [there, is, a, forest, fire, at, spot, pond, ,, geese, are, fleeing, across, the, street, ,, i, ...\n",
       "3                                                    [apocalypse, lighting, ., #, spokane, #, wildfires]\n",
       "4                                                 [typhoon, soudelor, kills, 28, in, china, and, taiwan]\n",
       "5                                                        [we, are, shaking, ..., it, is, an, earthquake]\n",
       "6       [they, would, probably, still, show, more, life, than, arsenal, did, yesterday, ,, eh, ?, eh, ?]\n",
       "7                                                                             [hey, !, how, are, you, ?]\n",
       "8                                                                                [what, a, nice, hat, ?]\n",
       "9                                                                                         [fuck, off, !]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "nasty-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations since they serve little value once we begin to analyze our data.\n",
    "punc = string.punctuation\n",
    "test['text'] = test['text'].apply(lambda x: [word for word in x if word not in punc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "economic-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                              [just, happened, a, terrible, car, crash]\n",
       "1                                [heard, about, earthquake, is, different, cities, stay, safe, everyone]\n",
       "2    [there, is, a, forest, fire, at, spot, pond, geese, are, fleeing, across, the, street, i, can, n...\n",
       "3                                                             [apocalypse, lighting, spokane, wildfires]\n",
       "4                                                 [typhoon, soudelor, kills, 28, in, china, and, taiwan]\n",
       "5                                                        [we, are, shaking, ..., it, is, an, earthquake]\n",
       "6                [they, would, probably, still, show, more, life, than, arsenal, did, yesterday, eh, eh]\n",
       "7                                                                                   [hey, how, are, you]\n",
       "8                                                                                   [what, a, nice, hat]\n",
       "9                                                                                            [fuck, off]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "imposed-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords are typically useless words and do not add much meaning to a sentence\n",
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test['text'] = test['text'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hydraulic-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    [happened, terrible, car, crash]\n",
       "1        [heard, earthquake, different, cities, stay, safe, everyone]\n",
       "2    [forest, fire, spot, pond, geese, fleeing, across, street, save]\n",
       "3                          [apocalypse, lighting, spokane, wildfires]\n",
       "4                       [typhoon, soudelor, kills, 28, china, taiwan]\n",
       "5                                          [shaking, ..., earthquake]\n",
       "6    [would, probably, still, show, life, arsenal, yesterday, eh, eh]\n",
       "7                                                               [hey]\n",
       "8                                                         [nice, hat]\n",
       "9                                                              [fuck]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hazardous-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming is to reduce different forms of word usage into its root word. \n",
    "# For example, “drive”, “drove”, “driving”, “driven”, “driver” are derivatives of the word “drive” \n",
    "# stemming the word “pies” will often produce a root of “pi” whereas lemmatization will find the \n",
    "# morphological root of “pie”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "stunning-conversation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              [(happened, VBN), (terrible, JJ), (car, NN), (crash, NN)]\n",
       "1    [(heard, RB), (earthquake, NN), (different, JJ), (cities, NNS), (stay, VBP), (safe, JJ), (everyo...\n",
       "2    [(forest, JJS), (fire, NN), (spot, NN), (pond, NN), (geese, JJ), (fleeing, VBG), (across, IN), (...\n",
       "3                                   [(apocalypse, NN), (lighting, VBG), (spokane, NN), (wildfires, NNS)]\n",
       "4                     [(typhoon, NN), (soudelor, NN), (kills, VBZ), (28, CD), (china, NN), (taiwan, NN)]\n",
       "5                                                           [(shaking, VBG), (..., :), (earthquake, NN)]\n",
       "6    [(would, MD), (probably, RB), (still, RB), (show, VB), (life, NN), (arsenal, JJ), (yesterday, NN...\n",
       "7                                                                                            [(hey, NN)]\n",
       "8                                                                                [(nice, JJ), (hat, NN)]\n",
       "9                                                                                           [(fuck, NN)]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'] = test['text'].apply(nltk.tag.pos_tag)\n",
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "objective-victoria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   [(happened, v), (terrible, a), (car, n), (crash, n)]\n",
       "1        [(heard, r), (earthquake, n), (different, a), (cities, n), (stay, v), (safe, a), (everyone, n)]\n",
       "2    [(forest, a), (fire, n), (spot, n), (pond, n), (geese, a), (fleeing, v), (across, n), (street, n...\n",
       "3                                         [(apocalypse, n), (lighting, v), (spokane, n), (wildfires, n)]\n",
       "4                            [(typhoon, n), (soudelor, n), (kills, v), (28, n), (china, n), (taiwan, n)]\n",
       "5                                                              [(shaking, v), (..., n), (earthquake, n)]\n",
       "6    [(would, n), (probably, r), (still, r), (show, v), (life, n), (arsenal, a), (yesterday, n), (eh,...\n",
       "7                                                                                             [(hey, n)]\n",
       "8                                                                                  [(nice, a), (hat, n)]\n",
       "9                                                                                            [(fuck, n)]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "test['text'] = test['text'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "test.head(10).loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fossil-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wnl = WordNetLemmatizer()\n",
    "# test['text'] = test['text'].apply(lambda x: [wnl.lemmatize(word) for word in x])\n",
    "# test['text'] = test['text'].apply(lambda x: [wnl.lemmatize(tag) for tag in x])\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "test['text'] = test['text'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "animal-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-length",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-japanese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-impossible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-aggregate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
